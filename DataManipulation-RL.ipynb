{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DataManipulation-RL.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"MqScbkrDxmNk","colab_type":"code","outputId":"aa0a8d24-3481-426e-c37b-8e126e580b54","executionInfo":{"status":"ok","timestamp":1575920436394,"user_tz":360,"elapsed":18379,"user":{"displayName":"Anurag R Patil","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBHkZ5VgZETPUUX6xCoo620tp-UpvvOjD2EY-oz=s64","userId":"16779265669764360774"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"i98iDYPIyO2h","colab_type":"code","outputId":"94c07450-f0ce-4186-83a6-ef197e54068c","executionInfo":{"status":"ok","timestamp":1575920438148,"user_tz":360,"elapsed":144,"user":{"displayName":"Anurag R Patil","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBHkZ5VgZETPUUX6xCoo620tp-UpvvOjD2EY-oz=s64","userId":"16779265669764360774"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd \"/content/drive//My Drive/Colab/\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Fnn3evqR6wV-","colab_type":"code","colab":{}},"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from torch.utils.data import SubsetRandomSampler \n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.autograd import Variable\n","import math\n","import random"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7xij3S_sZm7f","colab_type":"text"},"source":["**Load CIFAR10**"]},{"cell_type":"code","metadata":{"id":"QxQH34BECQY5","colab_type":"code","outputId":"00ec7eef-b74c-4490-9039-ebaf394bf660","executionInfo":{"status":"ok","timestamp":1575920454399,"user_tz":360,"elapsed":11040,"user":{"displayName":"Anurag R Patil","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBHkZ5VgZETPUUX6xCoo620tp-UpvvOjD2EY-oz=s64","userId":"16779265669764360774"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["transform = transforms.Compose(\n","    [transforms.ToTensor()])\n","\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                        download=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, \n","                                          shuffle=True, num_workers=2)\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                       download=True, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n","                                         shuffle=False, num_workers=2)\n","classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kZky2W9lZubF","colab_type":"text"},"source":["### DownSample the Dataset"]},{"cell_type":"code","metadata":{"id":"wYhCJAOQKCA-","colab_type":"code","colab":{}},"source":["label_subsets = dict()\n","for i in range(0,10):\n","  label_subsets[i] = list()\n","for i in range(0, len(trainset)): \n","  label_subsets[trainset[i][1]].append(tuple((trainset[i][0],trainset[i][1])))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xrkKn-_UT3xV","colab_type":"code","colab":{}},"source":["from torch.utils.data import Dataset\n","\n","class MyDataset(Dataset):\n","    def __init__(self, l):\n","        self.samples = tuple(l)\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, idx):\n","        return self.samples[idx]\n","\n","# data set for each class\n","dataset_0 = MyDataset(label_subsets[0])\n","dataset_1 = MyDataset(label_subsets[1])\n","dataset_2 = MyDataset(label_subsets[2])\n","dataset_3 = MyDataset(label_subsets[3])\n","dataset_4 = MyDataset(label_subsets[4])\n","dataset_5 = MyDataset(label_subsets[5])\n","dataset_6 = MyDataset(label_subsets[6])\n","dataset_7 = MyDataset(label_subsets[7])\n","dataset_8 = MyDataset(label_subsets[8])\n","dataset_9 = MyDataset(label_subsets[9])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5a46uknsJ7aQ","colab_type":"code","colab":{}},"source":["subset_indices = np.random.randint(1,len(dataset_0),40)\n","\n","#new_set is the dataset with randomly picked 40 points from each class - part A (low data regime) - training\n","new_set_0 = torch.utils.data.Subset(dataset_0, subset_indices)\n","new_set_1 = torch.utils.data.Subset(dataset_1, subset_indices)\n","new_set_2 = torch.utils.data.Subset(dataset_2, subset_indices)\n","new_set_3 = torch.utils.data.Subset(dataset_3, subset_indices)\n","new_set_4 = torch.utils.data.Subset(dataset_4, subset_indices)\n","new_set_5 = torch.utils.data.Subset(dataset_5, subset_indices)\n","new_set_6 = torch.utils.data.Subset(dataset_6, subset_indices)\n","new_set_7 = torch.utils.data.Subset(dataset_7, subset_indices)\n","new_set_8 = torch.utils.data.Subset(dataset_8, subset_indices)\n","new_set_9 = torch.utils.data.Subset(dataset_9, subset_indices)\n","\n","sampled_train_dataset = torch.utils.data.ConcatDataset((new_set_0, new_set_1, new_set_2,new_set_3,new_set_4,new_set_5,new_set_6,new_set_7,new_set_8,new_set_9))\n","\n","sampled_train_loader = torch.utils.data.DataLoader(sampled_train_dataset, batch_size= 4,\n","                                          shuffle=True, num_workers=2)\n","\n","# #######generate validation dataset\n","subset_indices = np.random.randint(1,len(dataset_0),2)\n","\n","#new_set is the dataset with randomly picked 4 points from each class - part A (low data regime) - validation\n","new_setval_0 = torch.utils.data.Subset(dataset_0, subset_indices)\n","new_setval_1 = torch.utils.data.Subset(dataset_1, subset_indices)\n","new_setval_2 = torch.utils.data.Subset(dataset_2, subset_indices)\n","new_setval_3 = torch.utils.data.Subset(dataset_3, subset_indices)\n","new_setval_4 = torch.utils.data.Subset(dataset_4, subset_indices)\n","new_setval_5 = torch.utils.data.Subset(dataset_5, subset_indices)\n","new_setval_6 = torch.utils.data.Subset(dataset_6, subset_indices)\n","new_setval_7 = torch.utils.data.Subset(dataset_7, subset_indices)\n","new_setval_8 = torch.utils.data.Subset(dataset_8, subset_indices)\n","new_setval_9 = torch.utils.data.Subset(dataset_9, subset_indices)\n","\n","sampled_val_dataset = torch.utils.data.ConcatDataset((new_setval_0, new_setval_1, new_setval_2,new_setval_3,new_setval_4,new_setval_5,new_setval_6,new_setval_7,new_setval_8,new_setval_9))\n","\n","sampled_val_loader = torch.utils.data.DataLoader(sampled_val_dataset, batch_size= 20,\n","                                          shuffle=True, num_workers=2)\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-r7ccmvwJdhi","colab_type":"code","colab":{}},"source":["############imbalanced classes\n","subset_indices_1 = np.random.randint(1,len(dataset_0),100)\n","subset_indices_2 = np.random.randint(1,len(dataset_0),1000)\n","\n","#new_set is the dataset with randomly picked 40 points from each class - part A (low data regime) - training\n","new_set_imbal_0 = torch.utils.data.Subset(dataset_0, subset_indices_1)\n","new_set_imbal_1 = torch.utils.data.Subset(dataset_1, subset_indices_2)\n","\n","sampled_imbalanced_train_dataset = torch.utils.data.ConcatDataset((new_set_imbal_0, new_set_imbal_1))\n","\n","sampled_imbalanced_train_loader = torch.utils.data.DataLoader(sampled_imbalanced_train_dataset, batch_size= 4,\n","                                          shuffle=True, num_workers=2)\n","\n","# #######generate validation dataset\n","subset_indices_imbal = np.random.randint(1,len(dataset_0),10)\n","\n","#new_set is the dataset with randomly picked 4 points from each class - part A (low data regime) - validation\n","new_setval_imbal_0 = torch.utils.data.Subset(dataset_0, subset_indices_imbal)\n","new_setval_imbal_1 = torch.utils.data.Subset(dataset_1, subset_indices_imbal)\n","\n","\n","sampled_imbalanced_val_dataset = torch.utils.data.ConcatDataset((new_setval_imbal_0, new_setval_imbal_1))\n","\n","sampled_imbalanced_val_loader = torch.utils.data.DataLoader(sampled_imbalanced_val_dataset, batch_size= 20,\n","                                          shuffle=True, num_workers=2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"axce-d8qdWXO","colab_type":"code","outputId":"0b1fc45a-03df-4d4d-de84-08edc1582f81","executionInfo":{"status":"ok","timestamp":1575920493786,"user_tz":360,"elapsed":129,"user":{"displayName":"Anurag R Patil","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBHkZ5VgZETPUUX6xCoo620tp-UpvvOjD2EY-oz=s64","userId":"16779265669764360774"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["print(len(sampled_train_loader)) # batch size is 4\n","print(len(sampled_val_loader)) # batch size is 20\n","print(len(sampled_val_dataset))\n","print(len(sampled_val_dataset)) "],"execution_count":0,"outputs":[{"output_type":"stream","text":["100\n","1\n","20\n","20\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"D3jp7_prYr6S","colab_type":"code","outputId":"160279a1-c5d7-49d5-a371-e48055dbbdd3","executionInfo":{"status":"ok","timestamp":1575920496283,"user_tz":360,"elapsed":167,"user":{"displayName":"Anurag R Patil","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBHkZ5VgZETPUUX6xCoo620tp-UpvvOjD2EY-oz=s64","userId":"16779265669764360774"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["dataiter = iter(sampled_val_loader)\n","images, labels = dataiter.next()\n","# print(dataiter.next())\n","for i in range(2):\n","  \n","  print(len(images))\n","  print(np.bincount(labels))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["20\n","[2 2 2 2 2 2 2 2 2 2]\n","20\n","[2 2 2 2 2 2 2 2 2 2]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"u9SGxDmCGub_","outputId":"8a302b35-b05d-4c76-a526-213ca679514f","executionInfo":{"status":"ok","timestamp":1575920499264,"user_tz":360,"elapsed":729,"user":{"displayName":"Anurag R Patil","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBHkZ5VgZETPUUX6xCoo620tp-UpvvOjD2EY-oz=s64","userId":"16779265669764360774"}},"colab":{"base_uri":"https://localhost:8080/","height":138}},"source":["# functions to show an image\n","def imshow(img):\n","    # img = img / 2 + 0.5     # unnormalize\n","    npimg = img.numpy()\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","    plt.show()\n","\n","\n","# get some random training images\n","dataiter = iter(sampled_train_loader)\n","images, labels = dataiter.next()\n","# print(dataiter.next())\n","# show images\n","imshow(torchvision.utils.make_grid(images))\n","# print labels\n","# print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXAAAAB5CAYAAAAgYXpDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO29aZBk2XUe9t3cMyurKmvfurqr956e\nnsHsGAyAwQAzNIYgxREkmAZFy0MREWNbsk3acliAGQ7ZCv2QZAVp2SGRQog0YYsmRCwiQBAAAQ4G\nGAyW2Wd6el+rq6u61q4tq3LPvP5xzn3nZFVWdXV1o6szcL+Iisy67+V7995333vnnO8sxloLDw8P\nD4/mQ2inO+Dh4eHhsT34B7iHh4dHk8I/wD08PDyaFP4B7uHh4dGk8A9wDw8PjyaFf4B7eHh4NClu\n6QFujHnWGHPWGHPBGPPZ29UpDw8PD48bw2zXD9wYEwZwDsAvABgH8DqAX7PWnrp93fPw8PDw2AiR\nW/jtYwAuWGsvAYAx5osAngOw4QPcGOOjhjw8PDxuHnPW2p61jbdiQhkCcFX9P85tHh4eHh63F1ca\nNd6KBL4lGGNeAPDCz/o8Hh4eHj9vuJUH+ASAYfX/Lm6rg7X28wA+D3gTioeHh8ftxK2YUF4HcNAY\ns9cYEwPwaQBfvz3d8vDw8PC4EbYtgVtrK8aY/wbAXwEIA/gja+3Jmz3Ov//ivwQAzMxcC9q6MoMA\ngJbUgHQ0FOG2JACgqmT51VwOABCPxYO2qq1RP6tGdbpKHyH6sVHvr1qF9s+V8kFbR4J+G4/IycZm\n6Bj5YgUAkEol5PB0CJQqFWmzdIyq6nClRt/LlSrWosK/rdVtc2OQY/zO5/7but997o+eDr4X8jSu\nUz8Ss1mqleamZbAtaOvu7wIARIq0/5kfvRdsa0+3AgD6ju4K2vJ2FQBw35GRoK1WyAIAfvzyZQDA\nldH5YFtvXwYAkI51BG2T12cAAMPDcm0vvUO/Hbs4RceU6UOpUgYAPPbMsaAtlKb5OPmuKHz5Uon6\n9jD1rbVDlvZQP1Eznb3poG05PwsA+Be/+S2sxT/90x8DAKy7oBohtZ6M+x6mf/mTvvMaC62/xvWg\nY4Ts1m5Fi0rwbS1qNddf6YcbQkNvMyPjs+7eaLCfa9Pb3LnUbOCf/MbHGv5O7x9S81cu0zkvXx5d\nd87ublqb4Ug0aCuWaezz8wtBW39/HwBg8tpk0Ma3N9raaK2XeW0AQGcnrcVag75VqzIf4+O0trp6\nqB+p1pZg20p2BQAQicg1c2MJh2XuW1roWWVBx3XPLgCIqf3WIhTaulx9SzZwa+03AXzzVo7h4eHh\n4bE9/MxJzBuhsBQDAPR1vC9oa+M3VzQib6JylSSxaiCeyRusWKC338rKatCWyaToGFHZrxZII/RZ\nKoq0XSiRZJDQM1JZBgCMLcnbN8Rv3UquAADIsfQPADHWAPSbvMqSfbFcljaWwF1/wuqNG42wNKcl\njyKdyxgt79Qju1qUcZaoH6WaSBn3HhoBAFy9LpJKnE+Rz9I4090yzniSpNWZuVnpW4rOXyjJuboy\nJOXEYqSJpONdMs4stU1lrwdt16ZI07o+Nh20JS2NebCHpH4rU4WFRZLwL58SbSLdR/0cHGgP2to7\n6LwVS31bmJXrUl2lc41eFqepWFsBG8FJjnq2w3zdq1UlUVu6bhQSUS+Bw2wseW98FRtvs1rod3so\nCdJ9c+vD1rQUvV57ayC8rzuv3eS/unNtMY5E9pe2SJjmdHlJ7tupSdLCTlfPAwDK6l5KttCaLBRk\n/RUL9DyYmZkJ2q5N0hqP8jUz6v7q7qJ1UszLvR8ytP3ee++RY7BEPzlFa7dUkRnK52lt1aqiKlZY\nY47G5AFieA10dXcCAD70wcdkW+Tm5m8j+FB6Dw8PjyaFf4B7eHh4NCl23ITSkSE1ON0i6rvjBgpF\nUVFCTGI6k0S+KGpUiFW8aFjUnJYk2QccCQYANVbHyiVqW8mJmtueonO1J4XwuDJDpgghhwBraD/D\nTEkuJ6pYhIkJd3wAyOfpeOGomETKbE4JhVj1VipeldUyfc5yhY7hVPVGuHRJiJ10jNTEhRUZi41F\n6/oIACluq8To/MMHR4JtM1NLAIDVbDZoawuTaevC6amg7cwKmUlOvzsHAFhZ0NeFYCpirmiJkMms\nty0TtPV0khmmvY22QZmbrl0jFTYXkqWaYvNYd4cQsrkijfX8Berb4XsPBts6Bsk0897pM9IWFUJz\nLRyJVCnL/F2fJ3K2s7MzaHMmPjG5KHXYmQxMaG1TvSmM7SPGbixL1R83mNWgSa8V2kWO5Uh0a9cb\nZxy5Rttr9X2rU+2dqUj91tb/7kZoRIQ6wq+rU8xuzhTh7pGZGTG/RfkeiijzYqlE90smI+a0qq3w\nfpH6MUEcHaLhkGqjddfeLmvCkaOFIo1vZnYp2OaOG4mL00SZnQ/icenbwgL1PcukpyZOnSlO9+1m\nyMvgNzf9Cw8PDw+PuwI7LoG3pEiaqihCgF+qwdsYAGIxelsHuymiprubpLnV1ZWgrcgSupY8ikV6\nqxdLJBHGQyLptaXoLTw2JRJFoULvt7CSgKrsbuXOr90DHeFWU22OjHQuUIBIHokoTX9RuR3WgnFp\n6Yg+K2q/tQiFRHoosVtgz6C46o1OjAEAMq2xoK1SIAnT1qgfhbL0OxonybqtLFJufpbGN5+TeQ5X\nWINK0jwnUyK1tmXoXLVlOUaVBfredpGY0mk+VxsdY6hHUj4cOkhujAtl0RyujZM03FoVaaewRAdu\nq9A5zbLM3yO/ROTU4qIQspGo9Gk9eB6UxOkkwoV5Ics6M7TuEgnSHuskYZambGgzyhKAi23blMva\n/BhOihMSU+/fQPLeAnGmJcNG+zcU1LeA+uPSZ/9Ad9DW29dVt19Ju9PynBo1JqeQVNW9ccjs5t1p\nY6hOymUtWWlXDomESNSHDu+j4/Lz44i6tLWak56VG3LgVilt2RVyDlhZyfI25broJHAldXsJ3MPD\nw+PnCP4B7uHh4dGk2HETyvUFUi+0KuaIQWdeAcS3usQRTwlFIGRZRVleFULRcGSbVaaZMGh7LMp+\n2EaGPzpFJpdiWfuNk5pVqa1XJwuFAu+jfL7ZTBKKyDEqbA8KKRLOkTHVGqnltiZqolPLnLmHdgi7\nk2Mj3HP//uD7mbfJh3bf0b6gbbVMhEpEmZRSMfb1XiaTxLUZiaI0ZRrX1Gnxv94zQCaZjpSYP370\no58AAPYfI7PHC7/1t2WcrdTfH3z9naBt6iSRrcWC8sFnu8rY+CIAYGVITD99/fT99EXxG3/1VSIj\n79snROWxB+n7+THqz0s/eCPYdmGW/L/bOiQS7sNPSdzBerDpLCwmmoEBig5eWRGyeO46mWRSCTIp\ndXUIwemud6XOhEHHrdURlo7sdP/bNVvEylK/Ve1nHEHo/r+B2SY4hDraJjaRBp7k67bdCJOT5P9/\n+owQyc4PPKuI8hLHGDi/bqsG393XCwDYvXufHJf9tS+cOyt9qtAxnElCm0Zch8tVHS3NkdHK+SAw\nv7AJVEd+lziyU89HXz+tj1JRmT7ZDNraRia2l3/0vWBbLEymvr0jI0Hbh554AjcLL4F7eHh4NCl2\nXALPrlIUVqkopEKaJe9qVdpWc/R9ZdW5pMm7f3WFpLlIWAi6rk6SWjsyInWl2iknRr7ExKkafphz\npnQod7/AfQrryQoXEVrV5CtLD9llkS5XlkiqrJWF+KvwG7zGLlhl7erIr/VISMbCvAsicWlbi3JF\n3K0efWwEAFCAzF+qRIRbJiTue2eOjwIA3jtBeR8iKldDXwfljMgti1vgSpIi0ExNNIzeDEmd+3cd\nBgC8+ZOxYNtqja5tSJE9qYwL/1Subhwtu7JKZOaFizKWM+dJ8j59eS5om2NXxVzhXNA2VaD5nWIi\nOVsUrebtV0mLuO/RvUHb2LVL2BCh9dqbWwut7UKwtrSQJjJ7jcZ89eL5YNvhw6QRZLqFoGPlERUl\ngVu+uJZzptRUBGeINb+wmu/qOoldcn8EQZp1smEjF0f+rjlXd1z3K6slfO5vrZHL4NZk8NErlO/m\nD/7g/wrapiZJ4xveNRK0LWep7bXXfwoASCmu+b5H7gcAtKT2BG1nj9OcT4zKWigEzgw0l8mkSOAR\n5/qprq0be0VF2TqN301VJCr33gpL6rEWcRw4cJiI8nxBPcfaqfO97EwwfV3W9ZFjNJaTV+R+uefe\ne3Gz8BK4h4eHR5PCP8A9PDw8mhQ7bkIpcDKotlalK7HektdJa5gMzHFko/aZbGsjFWl3j4rQMpw2\nsvVQ0DZfIdNJgUnDgvIxnZ8cp+NG5biJFlJ/64PNXHQXnaumNq5w/qSlWfE3zrOJKBEWlS0d5shK\n63zJ5RhOXY3ElO8qR5hWKjIfa7E0J5FiA8Nk1pgYFZ/lpSx1rhSX8Z346SidK0rz1z8oJpSODKfv\nfb/MX5V9Z4vF5aCtfx/Nc6lMpq1Xvi0paV0CqL5dcm3jbKJKpiUNb5h9pZMt7DMPlfirQNsyav8o\nq7NlFQswepHMQIP9RHSllQlqfpGIx7BKbFbaguxi6qIoWfVW54yzr3wHRxJ+51t/GWx77/hbAICn\nPvpk0LZ77wEaZ1z57LP5zMUrlBXZbfl7TfU1xFGG640kGrX137WlY43JZYOD3FaUOCHb6dOScdpF\nKccT6x9DjijsiIvJL5Wi751dQnIfPUpr95knHw/aXLrXQoHuvXBEBhpx0doVMXVcHR0FACwrMnVo\nkMytly+RqW16Vkx4VU6E1dUtEaQuMd7MNUlxXC6Tua1YpH4cOnZfsK2fzSqL0xLVXNtiVKuGl8A9\nPDw8mhQ3lMCNMX8E4JcBzFhrj3FbJ4D/AGAEwCiAX7XWLmx0jM2QTJJUvJqTlJIuObrOiunyFfR1\n0RvXRf4BEl11fkLIw+uWpOeKVUn/85yTgKX5tCrUUOM3ckm9BIuGJVjVEVeMwXJOlkJJRVGydNTa\nJgdJswtRr4ounL38LgAgWnNJ9GUs4ShLYtrNqRLm42+conR8TKSHy+8SAdTfJxXvzrMb3ri6TGV2\nedp/gPr2vscOBNsWWGpdCMt1cWlww3mRZMvLJEFOzZGbWEe75LRJJel7SLmChZhE0ppOhF3YEkl2\nvVNRq2ClI5MRqbXbpe1V82ZL1CeXgTiWFm2sgyNe81MyljM/aVgjtg518Yym/hOQfBYtrURmPvJ+\ncQP75te+BAD4xjf+Imgb2Usk6iOPPBq0DQ9T1CDCJM1rLz5Xi8Tl3wGAqCu8oG7diiNCec0YLYFv\nO+3rze2/hR0BACsrQubnuRjI8oqsmcF+mo9OJtGHB0UDbE3Rej544GjQ9st/n4pI7N/VH7SVef24\nnCj1tRM4AlIRlifeOw4A+Fe/+3tB24GDREK/n137Tpw+FWx75wRpEdeXRevNTZNWGlKSfW2V2qb5\n3iivLgbbrl6h9ZdS5GhjknhzbEUC/2MAz65p+yyAF621BwG8yP97eHh4eNxB3FACt9a+bIwZWdP8\nHICn+PsXAHwfwD/aTgcWF/ktpoJqUgmSnjJpkQJaUmwX50CbqzNih11ZoW2rEXkLL1dIGq9BFVxg\np/wlfnNGUiKlxcL09tPZ+la5hFhZeRa68kwu+CA3K5JvppvsryN7JKjGuULqjHyD+8ld6Orpt/nc\ncoIK59zQwRsuCWEssnE2wpa0BJEsLNJYFpbEZr64SGNp7xObognTHA6NUFtHtwqOynEuirJoNakU\n28r7pcza9Umay5UYHb+mVJgKf9e5KJy9PxRX+SxY1nWZ4gpRsYGH2WYZU4ny01zeKqrmY3WJ+hli\nCXVY5dcotFM2whOXxoO2i1c2lsCDwJUbSpd8kZiPca5hgOS4KCip68c/ehkAcOaUSHNPfvhDAIAH\nHiCpvLVb5rYcaGgitUZZ68jX5FpVDH1PRF0WxUbhPptjreRdn7Oktq5Ntm1VUqdPpy0DQIgzAi4v\nyb3cknRSLR13cHB3sK2jnQLTFhZEiwxKr6n71gRZPuN15yY4yVsaDx+h+7EusG+M1spv/w//IwDg\n/kdFu3qCXSJPKqn8wjlyZxy7cDFoi7LtPcIVSkrL0u9pdodubxc7utlGcYft2sD7rLWutMsUgL7N\ndvbw8PDwuP24ZS8Ua601xmz46jDGvADghVs9j4eHh4dHPbb7AJ82xgxYayeNMQMAZjba0Vr7eQCf\nB4BGD/r2NLmutSRUone2KFQqohZdmiAVfZGj8KJx6XoB5KaWtUqt5EjJtrSoSsmkM8PQ/1eXVXRk\njvZPtgupkGCTQTWvCzqQ0lJll75aSdVeZFc6rTYnmcQcV1F6z/zCBwEApVki5uZmZH9X5V6nmay5\nOqC1jS+XI4QA4MABIsumpyS3yf5DpJr3tYlpYZ7rD7a00YTHFTHsLlUiIeadljTnpgnJtYqmqE/t\nUSLy8ssyH0V2E4soU0ej+p7lkiuSQf9HVLJ9Z0LR/E4+x2l7Y6pIRolMKJ3t1EcTEdNP+xCtsa6i\n5Na5mhUC6uawXlZxXqDhmLhh3vcQubVpo1d3L12Dr/7Zvw/aXnzpBwCAsVFS2Q8ffSjY1sGFKx64\nV8joMpulFnJikpvO0oJuYQLcpbkFgBDfTHW1PG8SjbwOt3sQXZW+VqG1s7QoJrNSkQi/ErusJhJy\nP3Z20xorKzJ/eobI+bmSyifEpDUMzVV3t5gX29mcZtQxIuwOmm6THD8FXqe791KE5cBu6ffBQ2Qq\ne+jhDwRt42MUUXn29OmgbfQi5X05c5JcShfmxRVxgc1GsfaOoG075pDtmlC+DuB5/v48gK9t8zge\nHh4eHtvEVtwI/xREWHYbY8YB/GMA/wzAnxljPgPgCoBf3W4Hkkl6080tyFt4eZnejnmVHazG7/9E\njF7lkbi4Hs0v0Zt28JBI4CO7yFHelWADgNOnKCtdgUuNlVZFWixwrpVKSQV7cFm2Bz4g2c+SnNns\nx39F7okrdSkm6FzvviOZ8FKt3Mdr8vYd7OZq7RwcMDcrJE47l+xqT8ulaW0hSaxW25jkOLRfpLTR\n4yTNzangnic+SkEEoYocY2aINICFZdIA9hk5hitK4YItACCeIEl5Rbl8pjgfxNw0lz4ryJxGOBAl\nnhTJ1wney8syZsPnaku38DElaKfMhFw1K/1wQVwllcQ/zFJXWwdNeAmiXUU40CvdL+vDTGxcHEMC\nYdaXSKt3LayXSfW/tYAMFBlp3yGS5j71678RtL3FOT9OnaQAqPFJ0ZoSnDVz+tqRoO0BJkpTLeKW\n2s1ax9QMBZBduyYK8WAvaVydnRJMVWOSr6rkt80ItKCAglFqUCCWb5F448mJxkSiNqBrUFbxaWXW\naF1wz5UxyVlTYjLwg09+OGirVaktFRftp8zXzwX/6RwnAemqXFBdnpNOlbdmcooDbEIcXFaQZ1E8\nQXO5b58QkLuGSOt98CGpPH/p3AkAwD/5Xygb54oia1fmSYsMKZJ2OxrOVrxQfm2DTU9v43weHh4e\nHrcJPhLTw8PDo0mx47lQTp4ltUKrw1EmY6Jh6Z5zAw6xr+bsoork47SNq6tC7Fy6QmaESEz2K1ZI\nrU7E6Fy7jvQG21xRhYvnJoO27Bztn1R+4GEXGsjpS7WKXKmS+jc/J/kNWkuk0rcqM8LF82TKGeOk\n9eWsmCSyrEit5sUEsC9Opo3aJkTUcNdI8P3kHPk4T10Sdfzo36fttZqYOK5eHKXzO9/6q5LuslDg\nSNO8nLPEJPDuvZKWNVtgMoZ96ssltaQqNBYX1QkAiQiZMZJJUXlrXLzC1Rpsz6jcKZw3pFwSs4Bl\nx3ij/OdXmJBeZX3cGlF5Zy7yb62Yx5547EEAwJdOvo51MA1MKIEZQRO9rlr7+pIHJvA31lGR9HHw\nsEQSZjrJFOJSzE5cEj/iRTZtfefl14K2Cs/p449/KGjraefanGyvm1ImlHfepN8O9ou6f8+DRJTq\neq6SR9Z1dT2hrXGzeTvCbPYKKz9ww/McUqS4i/ZNcarexXkxAy5dp3X00NFjQVuKCe/+ARnfEsdo\nlMqcYych92ghz+s1ImY690xpVSTmdY5PcTEYhYLcjy6aNKZST8c41XNrWu5zl98px2vTlOVeivLa\ndbEpwPZMKF4C9/Dw8GhS7LgE7iTNSER1xXK2OVXooMxuQuE4vdUmZqTE1u4eeusVc+I6FotSW5vK\ndNbbQ9JcqJcklcEhIS1cEoq2dtn/xFsUcXXlkkTtXbtM5OUCE4/huBzD5aKI6nwZJdIKQmmROMe4\nQnwoTWNZmRKJPZ0nt6I2lemswvOQUInp1+LsydHg+9XzRGYtzQg79PqPiSTLCPeFTCfNg5OGZ2dE\nAl9dJikmpeav4gpWZEWK79tFWozlzI4RJeWaGskHWaOq2DN5FFIZ4kK8DBNJuu5pJcVkF6lPZaWh\nFXktOFdRALD8PdFKklWrym55iknduHI7zAy14k7DSequwj0AdHYRaf3JT/4tAMA3vvKlYNvpU++u\n2//yKK2d3r5ROXCMrveuvZS/Y88u0SxPvEHz8tqbbwVt7b1E8PcOSNSnxc3n4bgp8OXWEZOh8Bqx\nH1JcwV2qvSNC8n30o0S7HTwopfRW86z1Ki0vz9kCy6yNVauimS9xgZX+niHpmtPolHYQYenaZQLN\n51VOICZOq8rddZWzqiaTMbUf513h8emiNYWC0zqVi/I2MkJ6CdzDw8OjSeEf4B4eHh5Nih03oUgy\nHHmXuGTuRr9eWM0ZHCECo2VATBJL7F/Z16uSv7fS0EJVVWU+zKoPq+Pjl0SlKTk11Upk1IEDdLyp\naTHXREOk0nUN0v6rJVHPUu1EgrRlxEc9xipYJiMmkT2HyZQzeZUqaXfvF3X+0D3k82tVWkrnOuuK\nJjRCuaqTdnFSI6WyvfkK1Qy8/zHx9c600hwmEjRHi0vKd5oj5ob6VWX7HKmEM1MSOdrKkavOjzhs\n65yhAQAtLYqwZLWyqlLGujqFEY6uraixuzGEVKKh7BJHnVbkXJ29ZDrJ8NzHkrJ42rvInDKvfM+v\nXLuK7cDcQjyibeAb7gpEtLAPfH+/JGQ7f47SluaVo/R1Hvvx904EbVe5MvsL/+V/BQCYnr4WbFti\nIlSnus1y5ZHodSG5Ozn+4FYiNjdFEImpnA/Yd7+iCnh0d7IJkdfm6oqste+/8goA4MWXXw7aHCka\nVSbYVJxMcFFO7rVvv5hhHnjgfXRuiDkyrYvJMEzg9+8igVWCMP6qTVvR2HrzZqXi0vuy2VCZj2q1\n8rr9t5qZV8NL4B4eHh5NirtAAqfPfE4kSFcCKaJcbLp6SXJcZOliYVFyf8xyjoErZ0V6qLFbViIp\n0rCTdmIxToBvVfkq98ZVrmkRJkxb20R67ukhSWVxidyM4lmRYhwZ2NEpkZuOOKtVRYqqzBOplpvn\navBW3sbvvE6ElA3JG333MJFOHZn1koJDVaVxbevk3B8lGXtbO7XpYLrsCo1hiCvKDw4OBtvOvkdk\n2ck3pTzcFKfw7RgWF6yBYdImCkwcOWkaAIpFdulT7mrxCEnsIbX0XEGHEMsT2WW5tk5SL6lq32Ap\ncVBFzrVmaL6Kq3TOxQXRJmqWfhuNqyjbTQTNTbmkW0oIsvEZCnnSrq6ryuUi4clJVzkydnJalcu7\nTuv/7LtvAgDSHZL74773kcZ65NiDQZu71+aUI8AyS7DpNF3PraaJ3TKMKwsomld3F5e/S4sG2sqk\n+dT4KABgNSuOCRd/QhGNbq4AJcUrjc6yu16FUzk/++wzwTZXKm1+RkjPe45SOtl4XFev5+OyY4Ke\njxirxFpbKTHBb60UHnHXz405rLWPyFoXVE9ienh4ePxcwT/APTw8PJoUO25CcWqIVZFdThsySSHQ\nrs2RKl8ukmrc2SL+lvfuJlOB9iV36khHhzg+lx05xqkk69R9VoFyKk3nCldfX5iTVLDnz3KCnAip\n75m0kJ6VItf4m5fKL7Ul+r5wXSI8+zqpv0WOwJxXiXJSbWTqiKsI0ldfexUA8JEnpcL5Wrz2Q0lj\n+fDDpDZ375HIsliCxtXXJz7WSVZdTZS2tbSJyaXMicTe+OmFoG2R+/vhocNyDPZNj/Pch2pippga\nozGvZsWcEWczRkRXfGdf2AKTtPkVMTetMLE6Pycqb4qjWnu7RF2tGV5HBbrwtZIyOzARNrBbTFuX\nrm5cwnV9XOXmaFTFZqtwpN6bb5Of9pSqUu6gTYlFVsuvz4upJc5k3Q++910AwEee+YVg232PUeKn\novKZjzPJ19Mj/uLX58kU6MjAeELMZLejYr0jr+NxuW8fePD9AID+XvHJnrpC91qe+1NR6yluOMJS\n+XW77LQdaXFgcFGRLn6iu1ueI9llWsM6AtKZOlpaZP1nMnTvJNis0tUlZlSXElebcpyJSJtJnLOE\nWx/a5zvGplUdzekjMT08PDx+jrDjErh7S+ooKMMpT58aleixDi42kGglguavIyJJdvXQ27FbvSWT\nTF5qosFJFS5KL6ZIi6tXya0sr6pmH4iQJDh1eSxom52kiMbjZ+jzXRUxGeL6kceO3CNj6SFpIDsv\nElDvrj0AgOXzJG20ZUTa6ePq9WfPidQfCqTVjUWhiSvibhWJkXtiW6dIO3v3kGR/+JBIOwMjpD2U\n2Y1LkyhHHyDi9PRbKjdMjo6x/x4hybIrJMmODFN+lGJWpGeXyiYRlfG5SM2wkh3KTvthSaiUUy5W\nVUdwinyS5nSzpaIQ32WWMFtaSaqMRmQw999LqXRPnpPreH1mk4IOLh/I+myyARFOjW7bZrLT+ghH\nPc+uXmiCXSizK+Lq2MpkZF6l6C1yMYvWhJxz1wBJmJcv07V66XviZtfdQ5ri7v2iNWUrdB0jCdFg\nOttp/gp8LeJxuWYuUtHeZP4TjSpLn+0q30hvF/UtYlXxEk4fnIhR39Ltsta6mGxfXZWoyDBLwwMD\nA0Hbx56hSvVRlm5LytW3q5sk9SVFFieTNNZuRYq7VM/vvEd1L7XDg9P0tUtk2BUtUSJxkaOTC46I\nV8+iiJPAVcEKu9XUvApeAvfw8PBoUuy4BB44yCtXujTbjh6LSg6S8HGSMGtVknIvtklASu4JsvPN\nqoCbjz7zcQBASGf74twFo0iedagAAB+DSURBVJdHAQBv/vQnwbaxKfrt4Jic82m2uQ32i6SSvIfs\nxgdeIu1gcVWCBCaHSbJuScqbtMhCS1ylNMwuk/Q3MkL7Z5SUMcOuXa5QAgAcPHQAAFCtblyEYHiv\nBIBEWTo7sHd/0FbNk8QxekEKS0Rb2JUpSXMfUnb3tn5aGvd/WOyH85yXpKVHScgldv3jEmVFZb92\noqyW26oc6JNTxTTcWTnFBHJKiu9xrmYZkY7yRVoDpZpINEXW5PJc6m4pK5JsiFNZ1srSk5HdpIm8\n97qsGYeGNvAGdcVuxfbt4FzMjnGhhnBIZVhcJW3wtKpif/EUudLFWmS/oWHKaZLpJS3o7XeOB9v+\n8i/+AgDwtz8l+3cOHAIAqESTiLLGGuKAFFuXWRHctn1EOIilqoLLlqeJHxroE/dVV8k9mqL1f/ih\nR6QfrWznrsr66+okiX7XoEjgH3qcbOu2Rsd6623R5Pfupfu10CP3nONxtGa0zMFOp86NAgByBVk7\nzgaeSKgiErzulIkfs+OUS2meazgWlPaW5meEjcg97Xicm8ENJXBjzLAx5iVjzCljzEljzG9xe6cx\n5rvGmPP82XGjY3l4eHh43D5sxYRSAfAPrbVHATwO4B8YY44C+CyAF621BwG8yP97eHh4eNwhbKWk\n2iSASf6eNcacBjAE4DlQrUwA+AKA7wP4RzfbAaeGhpRbWZzTrF5slaT1+SRFnj32YWo78JW/DLYt\ncaRfpktcBlfYxaezS6K8chwt6PKepFvFTFEdJwLowV4hJSNPPAsAmMyqNKtLpHJXPvlLAICnwnL8\nL58dBQAsF4U0qRRJddSpJDuYnCpzdOb8ohCQ8wtkitDqakeGlJuCKvKwFh/5uCJOuZbi6rSYEcbO\nkzno3ClxU/tQlkwz/ftYfRaNEAkmfI88LCaU5Ry1heOijhdmuU4mk2/ajTDBkamrKiqywGagitJX\nnQtiJc+1DAuiVlZT1BZTtRRXOIVoUeWisCHarxJiF1GVBvf0iYvcJgNMJX/G6VO3CDcLkTD17dh9\nUpXepV7taBfz0cQFymmztCjX9uIord33f5TWa/8eSbf6pS/8WwDAV7/650Hbf/apTwMA2npHgrbl\nmkufyvNm5Ro0qpfpzEZbjdiMsJOCrgv5ve+9BADIZMSc0dJGa72nn8wqx0+fC7ZN8n0SUQUgOtro\nHn7+P/87QVuC69Y6M11/nzwXkkzOulqhADDJuWSyyuzWww4RTzxCuVOWF2UNOzK3pNafW5OQ5Y/l\nGTIRBdGn2nXWONdCNc+4edyUDdwYMwLgQQCvAujjhzsATAHo2+A3LwB4YRt98/Dw8PDYBFt+gBtj\n0gC+AuC3rbXL9TH81ppGdZdo2+cBfJ6PsW4f7fjusDJH0varb1wO2hL803kumzYxI2TcWI1c7rQj\n/vAIB4WoCuouX0eF35yrKmhnfo6k7GKbuE+dvUbS9tVZyXeyxO6GCdYSrkflzezIw7PvSVBN3AX6\nGHk1L7IkkWct4dqEBP5YJmg6uoWUdCWc4rGN39HJVjl+KwcDVdXYs3yu0YuSQ6NaI63gwfeTe9a+\nY0IEpftdwI1ICG1JNzdyrmiCJLdJTpQfDomkPL9I872iApWGOa/L6rK48VUKnCeDXdhaEuJqNnaN\njlsICbF56D4i66wida/PkCzRwUUqdE6KiTFaK2VFp07Pyvq5VTSSQgO3wxtIqIatmJUGu7nEjrsV\nGX2Ey4lNjMm9sWcf5fLo4ICVNkWKP/E0SeUXzwix+Vff+iYA4OlnfyVoS/WRU4DL/aFXWm0TCXyr\ncCRmQmXtm2Bt9tqsSL5799N62rWf7q/JCXFjza/Qek5EZf3NrGZ5m5DirlxZKkmPt0y7PBecVpNb\nlRwr0+w4sHe3OEa4bJwzo0QgV0uiQQcjV3MQY+k6HBb35miNi7lw5sGQFZKyUqTvUfVc+JkF8hhj\noqCH959Ya7/KzdPGmAHePgBgZqPfe3h4eHjcfmzFC8UA+EMAp621v6s2fR3A8/z9eQBfu/3d8/Dw\n8PDYCFsxoXwQwN8F8J4x5h1u+58B/DMAf2aM+QyAKwB+dTsdCHxMFWniPHOPJ0WV7ugiH9AJJgo1\ngRXJkVlj+poQdN/85rfp+HVVxDlfAZNmERX96VTHPy6IahWZofwrHSlJ4zq/6ooaUD9aVDJ4y36c\naRXhdvEURWx2dEiuhmKxPvIxooiPUnl9+kpHLBWL0re1+NH3xVd4/wFSBReui5liIUdmGF0BfOYS\nRVG+Mksmn7lxMbk8/iTlDdk9LARQPk/HW14SUtdyhF2VI+iWlVlqbpqrd9dkmbWwCl1U16XA+UuK\neTKTZNrFlHNunNTrkWOi3u45Qn0LKxNKiPPcRDlibm5Bcp3YGF2X+x6VauanzozyNzFfBfuva7l5\nuMt3I0tD4G9t1pOqVT6IM1MBwJMf/08AAFcvS7zC0XtoXDEm5ctqXp76OJHt+w5JJOaL//HL9Pkd\ncQT4xHNkTkm2MmGuCqFYR77dQorZwX66pr/5/G8EbdOc36ZUlUmKJ2kMcwtkOhufEj/9sDNT6LSs\nYTLZtSTFdOFI8SrHBmTahby2VVp/VZWXJMOFWCbGpcjHqeNvAwBOvkV5iFIqatuRkkVd45JTJ8dV\nZOW1cUoXXeb0vUbFLbhvuujKNgIxt+SF8go2Ns88ffOn9PDw8PC4HdjxSMyKq/CsEr27DH+7e4W8\niXMulMUJequViiIt2tD6BOvOOhQNKwmcP2suR4EiFQxLQFoO6hokIvGTzz0XtJ08R9n5zpwi4nTm\nmpSvyjMJV64JoeIqUi8vi6ugy/2xbz+NL18QqTVfpHlYWBLpOc9J/HX04lpcOSNE6/g5klpzOZHY\nQ8yIRawKFeNX/jTnhbj6XZGsz5ygvCEPPiDX4N57KHLUST0AkExS34uzJG2fOSUS7e5einob7hFC\n9vKb5NKXVeXNkgnWTjh/yVxRFTUAjT0ckqX66iskHQ33iuNTPERS1CTnhFkuCbk8fIBc0hbyIpWX\nw6pAxBqIVrg+78lWsfXdOSIPjaLw1sdAZnopMrVdlegLc34Z24AJNTxv+w4dDdoKT/8iAODbX/n/\ngra2730HAPDk0yThR1qECK3UXHmxDbt/Q8TZDfTxRx8L2pxr6MKyXKsf/oQk3nKO1odRbna1IKeI\naN8hzsS4vCj3y7f/kkjavkEi3XX+mksXaG0llAvx4iJp2qePvxu0vfTXlNnR5UTJKs2yws+PalWe\nFj1cyu+R+w4FbZEoSe0fePQB6r+SwEP8pNk1LJHc4W3QmD4XioeHh0eTwj/APTw8PJoUO25CcQma\n2jvaVSupVqs1UXOLWVKDBneRypFMSQRk2ZlOlEnE1dWsS1PLKkqUWcO2dlGjnLmhWpFjDPSS6n3h\n4mjQll9hkwETLzqiMEgvGRJV6NlfIj/cl/76e0FbDxOys5y830TE97yzh8iefEH8nhe5EnlWRd+t\nhVE5pNwQMimJNuvsoPlanhPzxHKWzA19IzTOdFrU5kvvkZ/xd7/1RtB29l2Kiju0X0wXe3cTeVTl\n6NOhVrmOQ5yIKr8q6mcuS51rT0sCoyoX1igYugbLBRlnPENr4fLFS0FbNMxksWIII2w+WGLTU6pH\nSOODx0itnVmV416dX5/ESlBb8wlxyjbrZR4xtehIu8ARfN3+jXyoba1BZKjbT+/OUcd6Xdvgk46h\nIydNcFxpG95HEbh9e4XYvDxJ66L6EkVHPvX0x4NtkTitnXoLDUdiblHtd5HWuiZmjc1Gc7Nihsyt\n0ppMcOGPmkqlW2ESv6pNn5yWdeG6mBCjPA+pFnIwOPneiWDbG28QYR9VMSM5Lh6RjMhx7z9Cc+SS\nWC2uiD96K0cYL2TFjBvnZGCPHJKiIQ89RFG18Q66p8sr0sdalNb1SlkmNayq1m8VXgL38PDwaFLs\nuAQeY7eykJJK5q8TqeDc7QCgr5eIzT1DRIgdOTASbKuydKETrLsk7bptbVRca1rewi6tbbmiUqXy\nb3VJsGyOJLyVOZKeKzURfWtMahQUIbX/IOWleOXlHwZtblyRKLs3Kalu6hq5MhWUe5Er66RdpdYi\nFJL9HW+bTEo/aqAxFKoi0RTYFXMPp9g8eM+BYFuOIyU706rYRIb6e/+xI0Fbe5qkhmiMJKtlRbTm\nqyQdjarq5wnOQXFtSirP23Y6xpH3Uz6XmWnREs6+Mwqg3svuyMERAEBbXBF/THDF20jqKippZjXH\nWl5GtIPhPc5V8SLWYrP0qZtFVtYFGt+OHKzBSTdv3OwUQTcUkZdi6fMTf+s/DdpWl4ng/eF3iQD8\n4Q++H2xzxKYxqvhAcPytSeCuuIJOU+vu24unJHL5z7/8FTouE4BRdYlLHO2rXQBTXaQ1vvRX4hIZ\nT9E6bWulz0yr3OeH99Na7xqSwiYnf/ImACCZl1jE7h7SMsv3khT9wSdk7Hta6LH5gzfeCdreukAa\naywrzgodJZLQcyV2W16S6N/k7hEAwMqSPD+q23DT9BK4h4eHR5PCP8A9PDw8mhQ7bkIJc5RhuSzk\nhotqOv6ukA8RJh7lU9WoY3W5UY26iApzdNuduSYUbmBeUWqMqyLtKrQDQJYJOVeXL6yO4arcF1Uk\n3NICERe6GneYzUYFTpAzcXUi2DY/T2pWVKVPTbcQiZTgyiuN0DsgpJ1l00V3n6oYYuhcqyWZj0iU\nzA1z02SyOnSfqJX3f5AiH9ujYnaYuURmo9felEr1rWk616OPkI94KC4qtZuaQw+JaeadH5PJ4vXj\nEjl65CNEMtZ4jvqHFMHJU1/Iiomoc4DMaYmakKOzk9S3oX0j9LuojP2N14h8zVohMYf3bjyXjdYC\nNkmf2pCUdAGWG57lxthqqtat/E63uf62t0sNljZO4/rMJyjm4Qff/kaw7dS75Hd/+AGpjmPtzcl+\npTJdv5kZMVPEmNBcPCOJuWbOE1ldYZKvu1WcFUyFI3uVeay8RAvk7LREUV6dJ/NcuoXWwKf+5t8I\ntu0aIBNs/y6J7H01TL7n7QuyPnb3EAH/VonaJi8JAblrL90n+7pl/s6PUfzDFRU5+jg/b8Ku3qky\nz7aySam7W8ann1VbhZfAPTw8PJoUOy6BO+Glpis2s1SuPatKFZaGnRtVcX3kmpaEXN26kIrEdFKI\nk5pjMckxUeUoqZB6pxWdK58SaCT4yolYiijk48d0ykyWrtvaxKUvniBS5fzbrwEAcjkh/jo7KcKu\nt0dykHSz22FUpXZdi127JWJybpaIlGJVyNcPP/swAGDqqkSsHX+FJGmXxnUlJ+Th7iPUj8Wrcs6T\nZ0jKWLkukkSmi6SckQM0vrwVCSTaSRJ+vCbXIMdufp1t4sKZbolxv0nKmZ8UImjXMB13eVVIzzGu\nfdodFVK3UKFjTF6n/eZUEY7xS6TVDN8jc3p9euPiGG6d1NfE3Di5SWMJ/NbZy9txjM2g77kaX6OO\nHpIuP/ZxkVqrHNWaUwUPklyzMmTkHtoMbii6ovzrr74OALgyKnldYlx0Y4HdBwvzqhBKN62nWFKI\n9dEJkuitugYu15EjbscnRMN94zU6J94UAvK980Si7lWas+V6nZkMScj3PvBosK2b8yUdOyxk/kf+\nBkW3tobk3oi7ohFt9DxoVfvXuFZvXKVf3k5tVS+Be3h4eDQpdlwCt+yUH1X2n/Y2klAjMd09En2d\nvbtO2g4CHupKhq9rczbwaJSOG4/Lm9wFFOnSZ86xvqIkFVdOyeVB0FKSy2cRjcpxe3vJ5nZ1fDZo\nu8BlsfJcYKKzUwJoBvvJ9tbdI7kunLtjX8/GdaMvXxiVfpTo7V62YiNenCYpO1SROV1dJmkoFKWx\n92Tk+BdPTfCnuD7VLB030yZS19F7yC1rjCWh7t1ie+7gvB2XTyu7ZwvN6ZPP3h+0mVaSUGosTyQT\n4vY1xRnrenpFel4cJyn+ylWRCNta+LfdNM6CKsvWw8U3Du6TIIu5/MZBUTeL2yEp304p/kY28KCM\noQ5CY2t9mUurtfcIHxIDzelqXrSg3CrboxXXsBkcJ+VK9QHAyTHiQ86NS5BWge3F1RCtCaNs7df5\n1qzmRYovhtg9UeUZMXwv19jGPjo6Gmzrbae10NMn+Xme+uAHAAB7JmS/9nbS7n71mU8AAFo75H5M\nucISyv0310Ljqpn1c1oLuaBC0TpdQFY9vATu4eHh8XMD/wD38PDwaFLc0IRijEkAeBlAnPf/srX2\nHxtj9gL4IoAuAG8C+LvW2o1zdG6AJOcVMIoyci6CqaSo6qsc4Rfliugh5UYYkIZ1eUmc2qJcC9kk\nEg45M4x2I+RoqYicM91Kx9CJ2xcXSaW35SofX/ZPJYnwaGmRIg+t7AZ1+fLZoG2O07d2d5PppJdd\nlgCgmyPL2tJC0KVSpJ5tpmBVVUraUJVTsEYVAcmuf7PjklI1xzUr093sXqnIxkunKPfDzKSozS2G\n+2HkXIODZHaZX6Ljzi+IKtvKfOnKkhA76U663jkrJGNhmo57fY7Odfh+Sck5w8UjTEUYbc46i9Pn\nR4O2Lq4J+vc+SW5wD8fEBPCtP6FiUYWCqN7tneK+tRbiRdjAZXDDX22AWzCN3E4Ss9666EhafXz3\nndZMubbe5BKLK7dUTozi1vKN4O4rl0IZAP7ef021zqdHxQVwgYt6LHBuosqKpEQusbl1VZH+RXY5\nduZIACgXaP3H2Vmht0tcbJ/80OMAgKFBKRoS4cmJz4h7rOU0tbUMRWSW1LMi2kLPm0pF7oNCmfpR\nqYkp2D1vkmF2hlCm1WiEnTJU4Pd2sBUJvAjgY9ba9wF4AMCzxpjHAfxzAL9nrT0AYAHAZ26tKx4e\nHh4eN4OtVOSxAJzPVZT/LICPAfg73P4FAP8rgN+/2Q64xH3RiLjThJjwOHhQ3tY//OGPAQDLi+Rq\nZpQzv3NpCodFGi6ya1wducFv2kaEkSM4wyrLm3Nn1JJQngkU9+aHkkaXl7O8TaSBiWvkjqQDlTo7\nSMru6SE3o9ZWVck6xrlFIqrMFJO5aZW7ZS06M+KmWC7RHO27T6SMaxMklcxPC3nXy7lB+nqZXFF5\nXe65lwJdDh6U6/L69ymg49gRyWI3xoELhSr9dnlSJPyLF4gIHeiVvu07QH2anFXZ3TqIoBw9Q2Tn\n2BkpCtHaRWNOpeXa9uwnAio3L2MZ7CKJOpcjkeadd18Ptq0yCdepMhQurGxMYjrJ9IYV5deso0bB\nMltFIBVvQ+re/DcbBx7V6gh4p3bQ/NVVpXeJFWsq1xBnAy03KCLRuBt0Hxbz4r7Zzrl9Og7IegIX\noKixxBupiYhai9B37VRQYRFWKQyouX6yw0FCOUMkuORZCHI/chofRPoky2berYESbdSBg0X2b64v\nwsHEsMpgaYJCGLSfjahtzjJwK5Fe2HpV+jDXw5wB8F1QBqBFK4UsxwEMbfDbF4wxbxhj3mi03cPD\nw8Nje9jSA9xaW7XWPgBgF4DHABy5wU/0bz9vrX3EWvvIjff28PDw8NgqbsoP3Fq7aIx5CcAHAGSM\nMRGWwncBmNj8140R45wAOiqsmCOVd6hf1Txk8nJ6Zpn7IupIsUTfdS6UApN61ep6lmBzlVOzPY2i\n7jZucLlQwitihhkfJ1NBTPmcd7ST+tnO0Yi9PeIH3t1Jan6LqoKdZN/ZhIpAW4uZafG1NpxaNtMp\nOUVqXLX9IsR0keF+HNg/AgBoU3kn7uniPCkzQhj19FLb4JCQruUEmYtyNTItDUdlLCdeJ+J2YU7y\nSJR302+LebkGxQKxnf1dZBqZGZNozhDXRAxXxLyT2k0+uYfuFV/e4gKd/9w5IsTyqtJ5ivNNTKs5\nise2FkG4FWy2nm6FiNyuGWZN67aOtf4I9XD3a0vLxmY9jXKZ7sflJYmHKBXYtFCTx5DLGeQcDMqQ\n+7dSy/OxlFnFPQd0DiNe62U2czYylun01e4ZlEzJ/ZVM8bj4nFCFF+SeV6lxeT7q4lOi7FvPz5SQ\nyoVSMezvbuVZUdvGUrmhBG6M6THGZPh7EsAvADgN4CUAn+LdngfwtZs/vYeHh4fHdrEVCXwAwBeM\nMWHQA//PrLXfMMacAvBFY8w/BfA2gD/cTgfKnKUsqSTUNEc1WVU66eH3UVXtH79GRNryipCH8kbW\nJBJ91pcpurks+40EGrMmK129ZEPvQ10N/u23KefC0KBIi0MDROr195K02qqkmESCJO+EyqcSEKyb\nlFzSFcnzRdr/pRclUb7rZToj87zCpcvyJZrLd4+LG9XACGk/586NqpPQx/lz54Km1l3Up/c/8yAA\nIKbIaOfaeOGMSP3ZVbqmk9OSkyWdoQOvsOYFpY3tGSIyNayC2PqGiAiduCiumeOTdI5kmaSpkYcl\nA+L8FEneU6NTQVtXZuOo1q2i8Rqo39YIW5WGt+9uuLVIzC2jQXZGV8ihZhuUgmuAKouXugJ9nqNl\nrXoM1bJ0PJcJtK5IBlw1eB0Zvb6Yi8vt46rAV5QDgXNu0BXl3XxFo7J2U6nUmm2iscX53tTEprvB\nag3cLx3SLeKsEASPx1SRlgbl+m6ErXihHAfwYIP2SyB7uIeHh4fHDsBHYnp4eHg0Ke6CZFb06RJM\nAUCViStNQA4PkUr/gYfvAwBMTAohNb9EalmpJBGTrvq19nV16k2lWq+mAbpm4A2SzAR5s0L8qUhM\ndmrXYxnqJ8LtgWMSXTjIbamEMxXJ4aOslulEXs50oiNC12KgV3y+xznd6vyi+GS3cQSkiYs62dJN\ndokom6xOvHYm2DZ6lYjHWEL6YZnUnZkUUrISouOePsO1JSMymFQ7+ZnnylJ1/PQFIhlzKh1wR5rP\nsUB+9PGEimZj1bizV3y43z1Bpp6EWh/tGfIln5ghMrPluqyPRU6ItTyn/PMvy9zcKjYzpdxu3I4E\nVzd7DKl/qeDugy06MrdmyFx47NEPBG0VTuhUa3AMd9ytz6lR3+oT2dWNt4G/vV2zTf82OGrdI6BB\n3xpYZ9emJQ5rcZmfcTq6Nd26cXTwRvASuIeHh0eTwvysk8bXnayekfDw8PDw2BrebBRL4yVwDw8P\njyaFf4B7eHh4NCn8A9zDw8OjSeEf4B4eHh5NijvtRjgHYJU/mxndaO4xNHv/geYfQ7P3H2j+MTRT\n//c0aryjXigAYIx5o9kzEzb7GJq9/0Dzj6HZ+w80/xiavf+AN6F4eHh4NC38A9zDw8OjSbETD/DP\n78A5bzeafQzN3n+g+cfQ7P0Hmn8Mzd7/O28D9/Dw8PC4PfAmFA8PD48mxR19gBtjnjXGnDXGXDDG\nfPZOnns7MMYMG2NeMsacMsacNMb8Frd3GmO+a4w5z5+3Xh3gZwguSv22MeYb/P9eY8yrfB3+gzEm\ndqNj7CSMMRljzJeNMWeMMaeNMR9owmvw3/MaOmGM+VNjTOJuvg7GmD8yxswYY06otoZzbgj/J4/j\nuDHmoZ3ruWCDMfzvvI6OG2P+o6s2xts+x2M4a4z5+M70+uZwxx7gXNHnXwP4RQBHAfyaMebonTr/\nNlEB8A+ttUcBPA7gH3CfPwvgRWvtQQAv8v93M34LVAbP4Z8D+D1r7QEACwA+syO92jr+FYBvW2uP\nAHgfaCxNcw2MMUMA/jsAj1hrjwEIA/g07u7r8McAnl3TttGc/yKAg/z3AoDfv0N9vBH+GOvH8F0A\nx6y19wM4B+BzAMD39acB3Mu/+Tf8zLqrcScl8McAXLDWXrLWlgB8EcBzd/D8Nw1r7aS19i3+ngU9\nOIZA/f4C7/YFAH9zZ3p4YxhjdgH4JQD/jv83AD4G4Mu8y93e/3YAT4JL9llrS9baRTTRNWBEACSN\nMREAKQCTuIuvg7X2ZQDza5o3mvPnAPw/lvBTUMHzAewwGo3BWvsdLsQOAD8FFWQHaAxftNYWrbWX\nAVxAE1Qcu5MP8CEAV9X/49zWFDDGjIBKy70KoM9a6wo9TgHo26FubQX/B4D/CYCrXtEFYFEt4rv9\nOuwFMAvg/2Yz0L8zxrSgia6BtXYCwL8EMAZ6cC8BeBPNdR2Ajee8We/t3wTwLf7elGPwJOYWYIxJ\nA/gKgN+21i7rbZbceO5KVx5jzC8DmLHWvrnTfbkFRAA8BOD3rbUPglIx1JlL7uZrAABsK34O9DIa\nBNCC9ap9U+Fun/MbwRjzOyAT6Z/sdF9uBXfyAT4BYFj9v4vb7moYY6Kgh/efWGu/ys3TTkXkz5mN\nfr/D+CCAXzHGjIJMVh8D2ZMzrMoDd/91GAcwbq19lf//MuiB3izXAACeAXDZWjtrrS0D+Cro2jTT\ndQA2nvOmureNMb8B4JcB/LoVP+qmGoPDnXyAvw7gIDPvMRBh8PU7eP6bBtuL/xDAaWvt76pNXwfw\nPH9/HsDX7nTftgJr7eestbustSOg+f6etfbXAbwE4FO8213bfwCw1k4BuGqMOcxNTwM4hSa5Bowx\nAI8bY1K8ptwYmuY6MDaa868D+C/YG+VxAEvK1HJXwRjzLMik+CvW2pza9HUAnzbGxI0xe0GE7Gs7\n0cebgrX2jv0B+ASI+b0I4Hfu5Lm32d8PgdTE4wDe4b9PgOzILwI4D+CvAXTudF+3MJanAHyDv+8D\nLc4LAL4EIL7T/btB3x8A8AZfhz8H0NFs1wDA/wbgDIATAP5fAPG7+ToA+FOQvb4M0oI+s9Gcg0r6\n/mu+r98DedvcrWO4ALJ1u/v5D9T+v8NjOAvgF3e6/1v585GYHh4eHk0KT2J6eHh4NCn8A9zDw8Oj\nSeEf4B4eHh5NCv8A9/Dw8GhS+Ae4h4eHR5PCP8A9PDw8mhT+Ae7h4eHRpPAPcA8PD48mxf8P/KAJ\nxkoLlQEAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"150DWw0XZ3yI","colab_type":"text"},"source":["**CNN to Classify**"]},{"cell_type":"code","metadata":{"id":"7gGXbubACe9w","colab_type":"code","colab":{}},"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 6, 5)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.conv2 = nn.Conv2d(6, 16, 5)\n","        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n","        self.fc2 = nn.Linear(120, 84)\n","        self.fc3 = nn.Linear(84, 10)\n","\n","    def forward(self, x):\n","        # x = self.pool(F.relu(self.conv1(x)))\n","        # x = self.pool(F.relu(self.conv2(x)))\n","        # x = x.view(-1, 16 * 5 * 5)\n","        # x = F.relu(self.fc1(x))\n","        # x = F.relu(self.fc2(x))\n","        # x = self.fc3(x)\n","        model_actor = torchvision.models.resnet34(pretrained=True)\n","        for param in model_actor.parameters():    \n","          param.requires_grad = False\n","\n","        # Parameters of newly constructed modules have requires_grad=True by default\n","        num_ftrs = model_actor.fc.in_features\n","        model_actor.fc = nn.Linear(num_ftrs, 10) \n","        \n","        action = model_actor(x)\n","       \n","        return action\n","\n","\n","net = Net()\n","# net = torchvision.models.resnet34(pretrained=False)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tfUJt9ncxAm9","colab_type":"code","outputId":"fca2f0c4-3707-4c9a-a083-0bf9e26b2b03","executionInfo":{"status":"error","timestamp":1575859788422,"user_tz":360,"elapsed":9832,"user":{"displayName":"Anurag R Patil","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBHkZ5VgZETPUUX6xCoo620tp-UpvvOjD2EY-oz=s64","userId":"16779265669764360774"}},"colab":{"base_uri":"https://localhost:8080/","height":664}},"source":["trainset_resnet = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                        download=True, transform=transform)\n","trainloader_resnet = torch.utils.data.DataLoader(trainset, batch_size=4,\n","                                          shuffle=True, num_workers=2)\n","for epoch in range(2):  # loop over the dataset multiple times\n","\n","    running_loss = 0.0\n","\n","    for i, data in enumerate(trainloader_resnet,0):\n","        # get the inputs; data is a list of [inputs, labels]\n","\n","        inputs, labels = data\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = net(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print statistics\n","        running_loss += loss.item()\n","      \n","        print('[%d, %5d] loss: %.3f' %\n","              (epoch + 1, i + 1, running_loss))\n","        if i % 2000 == 1999:    # print every 2000 mini-batches\n","          print('[%d, %5d] loss: %.3f' %\n","                (epoch + 1, i + 1, running_loss / 2000))\n","          running_loss = 0.\n","        \n","\n","print('Finished Training')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","[1,     1] loss: 2.902\n","[1,     2] loss: 5.662\n","[1,     3] loss: 8.284\n","[1,     4] loss: 10.954\n","[1,     5] loss: 13.757\n","[1,     6] loss: 16.409\n","[1,     7] loss: 18.628\n","[1,     8] loss: 21.155\n","[1,     9] loss: 23.744\n","[1,    10] loss: 26.262\n","[1,    11] loss: 29.633\n","[1,    12] loss: 31.707\n","[1,    13] loss: 34.429\n","[1,    14] loss: 37.452\n","[1,    15] loss: 40.623\n","[1,    16] loss: 43.887\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-71-1286ad1e8fa7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-70-4124b9710797>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# x = F.relu(self.fc2(x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# x = self.fc3(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mmodel_actor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet34\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_actor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m           \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mresnet34\u001b[0;34m(pretrained, progress, **kwargs)\u001b[0m\n\u001b[1;32m    241\u001b[0m     \"\"\"\n\u001b[1;32m    242\u001b[0m     return _resnet('resnet34', BasicBlock, [3, 4, 6, 3], pretrained, progress,\n\u001b[0;32m--> 243\u001b[0;31m                    **kwargs)\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_resnet\u001b[0;34m(arch, block, layers, pretrained, progress, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_resnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         state_dict = load_state_dict_from_url(model_urls[arch],\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, block, layers, num_classes, zero_init_residual, groups, width_per_group, replace_stride_with_dilation, norm_layer)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m                 \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkaiming_normal_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fan_out'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonlinearity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGroupNorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/init.py\u001b[0m in \u001b[0;36mkaiming_normal_\u001b[0;34m(tensor, a, mode, nonlinearity)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgain\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"w1-se_GHCo5D","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"Vy0KZDfiSFif","colab_type":"code","outputId":"a5d5c899-72b7-4446-d1ca-c18458aed810","executionInfo":{"status":"ok","timestamp":1575754004067,"user_tz":360,"elapsed":7505,"user":{"displayName":"Neha Agarwal","photoUrl":"","userId":"09286545786008981159"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["########################test the Net################################\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in testloader:\n","        images, labels = data\n","        outputs = net(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Accuracy of the network on the 10000 test images: %d %%' % (\n","    100 * correct / total))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy of the network on the 10000 test images: 10 %\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"a-EA3OeZaF2O","colab_type":"text"},"source":["**Reinforce**"]},{"cell_type":"code","metadata":{"id":"5EyPcXAqxDYM","colab_type":"code","colab":{}},"source":["class PiApproximationWithNN(nn.Module):\n","    def __init__(self,\n","                 state_dims,\n","                 num_actions,\n","                 alpha,\n","                 gamma):\n","        \"\"\"\n","        state_dims: the number of dimensions of state space\n","        action_dims: the number of possible actions\n","        alpha: learning rate\n","        gamma: decay factor\n","        \"\"\"\n","        # TODO: implement here\n","        super(PiApproximationWithNN, self).__init__()\n","        self.num_actions = num_actions\n","        self.gamma = gamma\n","        self.alpha = alpha\n","\n","        # the actor model\n","        self.model_actor = torchvision.models.resnet34(pretrained=True)\n","        for param in self.model_actor.parameters():    \n","          param.requires_grad = False\n","\n","        # Parameters of newly constructed modules have requires_grad=True by default\n","        self.num_ftrs_actor = self.model_actor.fc.in_features\n","        self.model_actor.fc = nn.Linear(self.num_ftrs_actor, 10)\n","        self.optimizer = optim.Adam(self.model_actor.parameters(), lr=alpha)\n","  \n","    \n","    def actor(self, state):\n","\n","        probs = self.model_actor(state)      #gives probability against different labels\n","\n","        highest_prob_action = []\n","        log_prob =[]\n","        for i in range(0,len(probs)):\n","\n","          prob = probs.data[i]\n","          highest = torch.argmax(prob).item() + 1 #add 1 for class number\n","          highest_prob_action.append(highest)\n","          log_prob.append(torch.log(torch.tensor(prob.data[highest-1].item())))\n","        \n","        return torch.tensor(highest_prob_action), torch.tensor(log_prob)\n","\n","    def discountedWeigthedRewards(self,rewards, weights):\n","\n","        discounted_rewards = []\n","        for t in range(len(rewards)):\n","            Gt = [0,0,0,0] \n","            pw = 0\n","            for r in rewards[t:]:\n","              # print(r)\n","              Gt = Gt + [x*0.9**pw for x in r]\n","              \n","              pw = pw + 1\n","\n","            discounted_rewards.append([a*b for a,b in zip(Gt,weights[t])]) \n","        return torch.tensor(discounted_rewards)\n","\n","    def update(self, returns, log_probs):\n","\n","      policy_gradient = []\n","      for log_prob, Gt in zip(log_probs, returns):\n","\n","          policy_gradient.append(torch.mul(log_prob, Gt))\n","      \n","      # print(policy_gradient)\n","     \n","      self.optimizer.zero_grad()\n","      policy_gradient = torch.stack(policy_gradient).sum()\n","    \n","      policy_gradient = Variable(policy_gradient, requires_grad=True)\n","      # print(policy_gradient.sum())\n","      policy_gradient.backward()\n","      self.optimizer.step()\n","\n","\n","      # return policy_gradient.sum().item()\n","\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fNKNr7mQL76R","colab_type":"code","colab":{}},"source":["class Data_Weight(object):\n","  def __init__(self, pi, alpha):\n","    self.pi = pi\n","    self.alpha = alpha\n","    self.weights = np.random.randint(1,2,400).reshape((100,4))\n","    self.decay = 0.1\n","\n","  def data_manipulation(self, data_loader):\n","    final_weight = []\n","    \n","    for runs in range(0, 20): #400 / size(data_loader)\n","      data_iter = iter(data_loader)\n","      images, labels = data_iter.next()\n","      \n","      # weights are assigned to each traning exmaple to adapt its effect on model training. -> model = learn weights.\n","      action, log_prob = self.pi.actor(images) \n","      for i in range(0, 20): #len(data_iter) = 20\n","        if(action[i]==labels[i]):\n","          final_weight.append(self.weights.reshape((400))[20*runs + i])\n","        else:\n","          final_weight.append(0.2)\n","    print(\"final_weight is \", str(final_weight))\n","\n","    # reshape the weight list\n","    np_array=np.asarray(final_weight)\n","    reshaped_array = np_array.reshape((100,4))\n","    final_weight = reshaped_array.tolist()\n","    return final_weight\n","\n","  def update(self, update_weights):\n","    update_weights = np.asarray(update_weights)\n","    # decay to avoid explosion\n","    self.weights = np.subtract(self.weights, self.weights * self.decay)\n","    self.weights = np.subtract(self.weights, update_weights*0.05)\n","    loss = np.sum(np.subtract(self.weights, update_weights*0.05))\n","    return loss\n","\n","\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fpHMeK43D1Tj","colab_type":"code","colab":{}},"source":["class env():\n","    def __init__(self,dataloader):\n","      self.dataloader = dataloader\n","        \n","    def step(self, action, state,trueLabels, step):\n","        # nextState = iter(state)    #move the data loader to the next batch\n","        \n","        reward = self.rewardFun(action, trueLabels)  #call the resnet over here for the current state(x in batches) and get its accuracy by taking the actual traindataset as the base\n","        if step == len(self.dataloader)-1:\n","          done = 1\n","        else:\n","          done = 0\n","        #done would be when you run out of data\n","        return  reward, done\n","    \n","    def reset(self):\n","        state = iter(dataloader) #reset the data loader to the inital value i.e the first batch. \n","        return state\n","\n","    def rewardFun(self, action, trueLabels):      \n","        # print(\"action\"+str(action))\n","        # print(\"trueLabels\"+str(trueLabels) )  \n","\n","        reward=[]\n","        for i in range(len(action)):\n","          if action[i]==trueLabels[i]:\n","            reward.append(1/len(action))\n","          else:\n","            reward.append(0.001)\n","        # print(reward)\n","        return reward"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hfnDn9UvZS94","colab_type":"code","colab":{}},"source":["def REINFORCE(\n","    env, #open-ai environment\n","    num_episodes:int,\n","    pi:PiApproximationWithNN,\n","    data_weights: Data_Weight\n","    ):\n","    \"\"\"\n","    implement REINFORCE algorithm with and without baseline.\n","\n","    input:\n","        env: target environment; openai gym\n","        num_episode: #episodes to iterate\n","        pi: policy\n","        V: baseline\n","    output:\n","        a list that includes the G_0 for every episodes.\n","    \"\"\"    \n","    max_episode_num = num_episodes\n","    \n","    numsteps = []\n","    avg_numsteps = []\n","    all_rewards = []\n","    all_losses = []\n","    \n","\n","    for episode in range(max_episode_num):\n","       \n","        stateLoader = sampled_train_loader # state is the dataloader. 4 images\n","        log_probs = []      # required for reinforce\n","        rewards = []        # accuracy after observing x batches. A sequential model. Check how NN perform for sequential models\n","        stateIter = iter(stateLoader)\n","        losses = []\n","       \n","        for steps in range(0,len(stateLoader)): # range (0, 100)\n","           \n","            state, trueLabels = stateIter.next()\n","            # print(\"len of state is \", len(state)) # = 4\n","            action, log_prob = pi.actor(state)\n","            reward, done = env.step(action,state,trueLabels, steps)\n","          \n","            log_probs.append(log_prob)\n","            rewards.append(reward)\n","            \n","            \n","\n","            if done:\n","              \n","              print(\"* * * after all steps len of reward is \", len(rewards)) # 4*100 = 400\n","              weights = data_weights.data_manipulation(sampled_val_loader) #400\n","              returns = pi.discountedWeigthedRewards(rewards, weights)\n","              # returns   = torch.cat(returns).detach()\n","              # log_probs = torch.cat(log_probs)\n","              pi.update(returns, log_probs) #update theta\n","              \n","              loss =data_weights.update(weights) #update fi\n","              print(loss)\n","              losses.append(loss)\n","              numsteps.append(steps)\n","              avg_numsteps.append(np.mean(numsteps[-10:]))\n","              all_rewards.append(np.sum(rewards))\n","              all_losses.append(losses)\n","              if episode % 1 == 0:\n","                print(\"episode: {}, total reward: {}, average_reward: {}, length: {}\\n\".format(episode, np.round(np.sum(rewards), decimals = 3),  np.round(np.mean(all_rewards[-10:]), decimals = 3), steps))\n","              break\n","          \n","            # state = new_state\n","    \n","    print(all_losses)\n","    plt.plot(all_rewards)\n","    \n","    plt.xlabel('Episode')\n","    plt.show()\n","\n","    return all_rewards, all_losses \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EqoF3eeKZikJ","colab_type":"code","colab":{}},"source":["def test_reinforce():\n","    envh = env(sampled_train_loader)\n","    policy_gamma = 0.9\n","    policy_alpha = 3e-4\n","    pi = PiApproximationWithNN(\n","        len(sampled_train_loader),\n","        10,\n","        policy_alpha, policy_gamma)########batch_size = 4\n","    alpha_weights = 0.01\n","    data_weights = Data_Weight(pi, alpha_weights)\n","    num_episodes = 20\n","    all_rewards, all_losses = REINFORCE(envh,num_episodes,pi, data_weights)\n","    return all_rewards, all_losses"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qlb0T2xpWwJo","colab_type":"code","outputId":"318966c7-e5b6-4027-e8b6-8b412b0e824b","executionInfo":{"status":"ok","timestamp":1575879350079,"user_tz":360,"elapsed":197457,"user":{"displayName":"Anurag R Patil","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBHkZ5VgZETPUUX6xCoo620tp-UpvvOjD2EY-oz=s64","userId":"16779265669764360774"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["all_rewards, all_losses = test_reinforce()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["* * * after all steps len of reward is  100\n","final_weight is  [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 1, 1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 1, 1, 0.2, 1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 1, 1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 1, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 1, 1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 1, 1, 0.2, 0.2, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 0.2, 0.2, 1, 1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 1, 0.2, 1, 0.2, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 0.2, 0.2]\n","347.20000000000005\n","episode: 0, total reward: 6.376, average_reward: 6.376, length: 99\n","\n","* * * after all steps len of reward is  100\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Rqgps7D4uz6_","colab_type":"code","outputId":"242245c3-99f9-466c-d030-d31dd12b39c3","executionInfo":{"status":"error","timestamp":1575879405886,"user_tz":360,"elapsed":1620,"user":{"displayName":"Anurag R Patil","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBHkZ5VgZETPUUX6xCoo620tp-UpvvOjD2EY-oz=s64","userId":"16779265669764360774"}},"colab":{"base_uri":"https://localhost:8080/","height":215}},"source":[""],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-d2c93dcb8d67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_rewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_numsteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all_rewards'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'all_rewards' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"lhus1quX32ie","colab_type":"text"},"source":["**PPO**"]},{"cell_type":"code","metadata":{"id":"MAT_JdQ-ZK_G","colab_type":"code","colab":{}},"source":["class Data_Weight(object):\n","  def __init__(self, pi, alpha):\n","    self.pi = pi\n","    self.alpha = alpha\n","    self.weights = np.random.randint(1,10,400).reshape((100,4))\n","    self.decay = 0.1\n","\n","  def data_manipulation(self, data_loader):\n","    final_weight = []\n","    \n","    for runs in range(0, 20): #400 / size(data_loader)\n","      data_iter = iter(data_loader)\n","      images, labels = data_iter.next()\n","      \n","      # weights are assigned to each traning exmaple to adapt its effect on model training. -> model = learn weights.\n","      action, log_prob = self.pi.actor(images) \n","      for i in range(0, 20): #len(data_iter) = 20\n","        if(action[i]==labels[i]):\n","          final_weight.append(self.weights.reshape((400))[20*runs + i])\n","        else:\n","          final_weight.append(1)\n","    print(\"final_weight is \", str(final_weight))\n","\n","    # reshape the weight list\n","    np_array=np.asarray(final_weight)\n","    reshaped_array = np_array.reshape((100,4))\n","    final_weight = reshaped_array.tolist()\n","    return final_weight\n","\n","  def update(self, update_weights):\n","    # decay to avoid explosion\n","    self.weights -= self.weights #* self.decay\n","    self.weights += update_weights\n","\n","class Data_Weight_imbal(object):\n","  def __init__(self, pi, alpha):\n","    self.pi = pi\n","    self.alpha = alpha\n","    self.weights = np.random.randint(2,4,1100).reshape((275,4))\n","    self.decay = 0.1\n","\n","  def data_manipulation(self, data_loader):\n","    final_weight = []\n","    \n","    for runs in range(0, 55): #400 / size(data_loader)\n","      data_iter = iter(data_loader)\n","      images, labels = data_iter.next()\n","      \n","      # weights are assigned to each traning exmaple to adapt its effect on model training. -> model = learn weights.\n","      action, log_prob = self.pi.actor(images) \n","      for i in range(0, 20): #len(data_iter) = 20\n","        if(action[i]==labels[i]):\n","          final_weight.append(self.weights.reshape((1100))[20*runs + i])\n","        else:\n","          final_weight.append(0.5)\n","    print(\"final_weight is \", str(final_weight))\n","\n","    # reshape the weight list\n","    np_array=np.asarray(final_weight)\n","    reshaped_array = np_array.reshape((275,4))\n","    final_weight = reshaped_array.tolist()\n","    return final_weight\n","\n","  def update(self, update_weights):\n","\n","  \n","    update_weights = np.asarray(update_weights)\n","    # decay to avoid explosion\n","    self.weights = np.subtract(self.weights, self.weights * self.decay)\n","    self.weights = np.subtract(self.weights, update_weights*0.05)\n","   \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1PpWBTDDE96r","colab_type":"code","colab":{}},"source":["class ActorCritic(nn.Module):\n","    def __init__(self,\n","                 state_dims,\n","                 num_actions,\n","                 alpha,\n","                 gamma):\n","        \"\"\"\n","        state_dims: the number of dimensions of state space\n","        action_dims: the number of possible actions\n","        alpha: learning rate\n","        gamma: decay factor\n","        \"\"\"\n","        # TODO: implement here\n","        super(ActorCritic, self).__init__()\n","        self.num_actions = num_actions\n","        self.gamma = gamma\n","        self.alpha = alpha\n","\n","        # the critic model \n","        self.model_critic = torchvision.models.resnet18(pretrained=False)\n","        for param in self.model_critic.parameters():    \n","           param.requires_grad = False\n","        self.num_ftrs_critic = self.model_critic.fc.in_features\n","        self.model_critic.fc = nn.Linear(self.num_ftrs_critic, 1) \n","\n","        # the actor model\n","        self.model_actor = torchvision.models.resnet34(pretrained=False)\n","        for param in self.model_actor.parameters():    \n","          param.requires_grad = False\n","\n","        # Parameters of newly constructed modules have requires_grad=True by default\n","        self.num_ftrs_actor = self.model_actor.fc.in_features\n","        self.model_actor.fc = nn.Linear(self.num_ftrs_actor, 2) \n","\n","\n","\n","        \n","\n","    def critic(self, x):\n","        \n","        value = self.model_critic(x)\n","\n","        return value\n","      \n","\n","        \n","    def actor(self, x):\n","        \n","        probs = self.model_actor(x)      #gives probability against different labels\n","\n","        highest_prob_action = []\n","        log_prob =[]\n","        for i in range(0,len(probs)):\n","\n","          prob = probs.data[i]\n","          highest = torch.argmax(prob).item() + 1 #add 1 for class number\n","          highest_prob_action.append(highest)\n","          log_prob.append(torch.log(torch.tensor(prob.data[highest-1].item())))\n","\n","        return torch.tensor(highest_prob_action), torch.tensor(log_prob)\n","\n","\n","      \n","      "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8F_FFUbEyRO8","colab_type":"code","colab":{}},"source":["def compute_gae(next_value, rewards, masks, values, gamma=0.99, tau=0.95):\n","    values = values + [next_value]\n","    gae = 0\n","    returns = []\n","    for step in reversed(range(len(rewards))):\n","        \n","        delta = torch.tensor(rewards[step]) + gamma * values[step + 1] * masks[step] - values[step]\n","        gae = delta + gamma * tau * masks[step] * gae\n","        returns.insert(0, gae + values[step])\n","    return returns"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XknfRSYA5L5V","colab_type":"code","colab":{}},"source":["policy_gamma = 0.9\n","alpha = 3e-4\n","model = ActorCritic(len(sampled_train_loader),10, alpha, policy_gamma)\n","optimizer = optim.Adam(model.parameters(), lr=alpha)\n","\n","\n","\n","def ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantage, values):\n","\n","    batch_size = states.size(0)\n","\n","    for _ in range(batch_size // mini_batch_size):\n","        rand_ids = np.random.randint(0, batch_size, mini_batch_size)\n","        # print(len(states[0]))\n","        # print(states[rand_ids, :])\n","        # print(actions[rand_ids, :])\n","        # print(log_probs[rand_ids, :])\n","        # print(returns[rand_ids, :])\n","        # print(advantage[rand_ids, :])\n","        # print(values[rand_ids, :])\n","        yield states[rand_ids, :], actions[rand_ids, :], log_probs[rand_ids, :], returns[rand_ids, :], advantage[rand_ids, :], values[rand_ids, :]\n","\n","\n","\n","def ppo_update(pi, ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantages, values, clip_param=0.2):\n","\n","    for _ in range(ppo_epochs):\n","        for state, action, old_log_probs, return_, advantage, value in ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantages, values):\n","\n","            # value = pi.critic(state)\n","\n","            new_log_probs = action\n","\n","            ratio = (new_log_probs - old_log_probs).exp()\n","\n","            surr1 = ratio * advantage\n","            surr2 = torch.clamp(ratio, 1.0 - clip_param, 1.0 + clip_param) * advantage\n","\n","            actor_loss  = - torch.min(surr1, surr2).mean()\n","            critic_loss = (return_ - value).pow(2).mean()\n","\n","            loss = 0.5 * critic_loss + actor_loss - 0.001 \n","\n","\n","            optimizer.zero_grad()\n","            loss = Variable(loss, requires_grad=True)\n","            loss.backward()\n","            optimizer.step()\n","\n","        \n","\n","\n","      \n","\n","\n","      \n","     "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jDrOuCDs36jM","colab_type":"code","colab":{}},"source":["def PPO(\n","    env, #open-ai environment\n","    num_episodes:int,\n","    pi:PiApproximationWithNN,\n","    data_weights: Data_Weight\n","    ):\n","    \"\"\"\n","    implement REINFORCE algorithm with and without baseline.\n","\n","    input:\n","        env: target environment; openai gym\n","        num_episode: #episodes to iterate\n","        pi: policy\n","        V: baseline\n","    output:\n","        a list that includes the G_0 for every episodes.\n","    \"\"\"    \n","    max_episode_num = num_episodes\n","    \n","    numsteps = []\n","    avg_numsteps = []\n","    all_rewards = []\n","    mini_batch_size  = 4\n","    ppo_epochs       = 4\n","    threshold_reward = -200\n","\n","    \n","\n","\n","\n","\n","    for episode in range(max_episode_num):\n","       \n","        # stateLoader = sampled_train_loader # state is the dataloader. 4 images\n","        stateLoader = sampled_imbalanced_train_loader\n","        log_probs = []      # required for reinforce\n","        rewards = []        # accuracy after observing x batches. A sequential model. Check how NN perform for sequential models\n","        values = []\n","        states = []\n","        actions = []\n","        masks = []\n","     \n","\n","        stateIter = iter(stateLoader)\n","       \n","        for steps in range(0,len(stateLoader)): # range (0, 100)\n","           \n","            state, trueLabels = stateIter.next()\n","  \n","            value = pi.critic(state)\n","            action, log_prob = pi.actor(state)\n","            reward, done = env.step(action,state,trueLabels, steps)\n","\n","            log_probs.append(log_prob)\n","            values.append(value)\n","            rewards.append(reward)\n","            masks.append(torch.FloatTensor(1))\n","     \n","            # print(value)\n","            states.append(state)\n","            actions.append(action)\n","\n","            # log_probs = [item for sublist in log_probs_list for item in sublist]\n","            # rewards = [item for sublist in rewards_list for item in sublist]\n","\n","            \n","            \n","\n","            if done:\n","              \n","              # print(\"* * * after all steps len of reward is \", len(rewards)) # 4*100 = 400\n","\n","              # weights = data_weights.data_manipulation(sampled_val_loader) #400\n","\n","              weights = data_weights.data_manipulation(sampled_imbalanced_val_loader)\n","              # returns = pi.discountedWeigthedRewards(rewards, weights)\n","              next_value = value\n","              returns = compute_gae(next_value, rewards, masks, values)\n","              returns   = torch.stack(returns).detach()\n","              log_probs = torch.stack(log_probs).detach()\n","              values    = torch.stack(values).detach()\n","              states    = torch.stack(states)\n","              actions   = torch.stack(actions)\n","              advantage = returns - values\n","\n","              # pi.update(rewards, log_probs, weighted_reward) #update theta\n","              ppo_update(pi, ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantage, values)\n","              data_weights.update(weights) #update fi\n","\n","              numsteps.append(steps)\n","              avg_numsteps.append(np.mean(numsteps[-10:]))\n","              all_rewards.append(np.sum(rewards))\n","              if episode % 1 == 0:\n","                print(\"episode: {}, total reward: {}, average_reward: {}, length: {}\\n\".format(episode, np.round(np.sum(rewards), decimals = 3),  np.round(np.mean(all_rewards[-10:]), decimals = 3), steps))\n","              break\n","          \n","            # state = new_state\n","    \n","    plt.plot(all_rewards)\n","    \n","    plt.xlabel('Episode')\n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5YoxqbWW4NDJ","colab_type":"code","outputId":"4b032eaa-e53c-4e19-fdab-c74a09970e14","executionInfo":{"status":"error","timestamp":1575932105281,"user_tz":360,"elapsed":2370,"user":{"displayName":"Anurag R Patil","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBHkZ5VgZETPUUX6xCoo620tp-UpvvOjD2EY-oz=s64","userId":"16779265669764360774"}},"colab":{"base_uri":"https://localhost:8080/","height":341}},"source":["# envh = env(sampled_train_loader)\n","envh = env(sampled_imbalanced_train_loader)\n","policy_gamma = 0.9\n","# policy_alpha = 3e-4\n","# pi = ActorCritic(len(sampled_train_loader),10, alpha, policy_gamma)\n","pi = ActorCritic(len(sampled_imbalanced_train_loader),10, alpha, policy_gamma)\n","# pi = PiApproximationWithNN(\n","#     len(sampled_train_loader),\n","#     10,\n","#     policy_alpha, policy_gamma)########batch_size = 4\n","\n","alpha_weights = 0.01\n","# data_weights = Data_Weight(pi, alpha_weights)\n","data_weights = Data_Weight_imbal(pi, alpha_weights)\n","num_episodes = 20\n","\n","PPO(envh,num_episodes,pi, data_weights)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-125-573816da9fea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mnum_episodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mPPO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_episodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-116-45b299bb9279>\u001b[0m in \u001b[0;36mPPO\u001b[0;34m(env, num_episodes, pi, data_weights)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrueLabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-78-94027617fc60>\u001b[0m in \u001b[0;36mactor\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_actor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m#gives probability against different labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mhighest_prob_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0midentity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"QvedPWwQ4XC5","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UnLs1QbMdBJ-","colab_type":"text"},"source":["**One step AC**"]},{"cell_type":"code","metadata":{"id":"HIQxBRqddEKf","colab_type":"code","colab":{}},"source":["class SAC(nn.Module):\n","    def __init__(self,\n","                 state_dims,\n","                 num_actions,\n","                 alpha,\n","                 gamma):\n","        \"\"\"\n","        state_dims: the number of dimensions of state space\n","        action_dims: the number of possible actions\n","        alpha: learning rate\n","        gamma: decay factor\n","        \"\"\"\n","        # TODO: implement here\n","        super(ActorCritic, self).__init__()\n","        self.num_actions = num_actions\n","        self.gamma = gamma\n","        self.alpha = alpha\n","\n","        # the critic model \n","        self.model_critic = torchvision.models.resnet18(pretrained=True)\n","        for param in self.model_critic.parameters():    \n","           param.requires_grad = False\n","        self.num_ftrs_critic = self.model_critic.fc.in_features\n","        self.model_critic.fc = nn.Linear(self.num_ftrs_critic, 1) \n","\n","        # the actor model\n","        self.model_actor = torchvision.models.resnet34(pretrained=True)\n","        for param in self.model_actor.parameters():    \n","          param.requires_grad = False\n","\n","        # Parameters of newly constructed modules have requires_grad=True by default\n","        self.num_ftrs_actor = self.model_actor.fc.in_features\n","        self.model_actor.fc = nn.Linear(self.num_ftrs_actor, 10) \n","\n","        # the soft Q model \n","        self.model_softQ = torchvision.models.resnet50(pretrained=True)\n","        for param in self.model_softQ.parameters():    \n","           param.requires_grad = False\n","        self.num_ftrs_softQ = self.model_softQ.fc.in_features\n","        self.model_softQ.fc = nn.Linear(self.num_ftrs_softQ, 1) \n","\n","\n","    def softQ(self,state,action):\n","      x = torch.cat([state,action])\n","      softQ_value = self.model_softQ(x)\n","      return softQ_value \n","\n","    def critic(self, x):\n","        \n","        value = self.model_critic(x)\n","\n","        return value\n","      \n","\n","        \n","    def actor(self, x):\n","        \n","        probs = self.model_actor(x)      #gives probability against different labels\n","\n","        highest_prob_action = []\n","        log_prob =[]\n","        for i in range(0,len(probs)):\n","\n","          prob = probs.data[i]\n","          highest = torch.argmax(prob).item() + 1 #add 1 for class number\n","          highest_prob_action.append(highest)\n","          log_prob.append(torch.log(torch.tensor(prob.data[highest-1].item())))\n","\n","        return torch.tensor(highest_prob_action), torch.tensor(log_prob)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"c5AAOM6ygBuw","colab_type":"code","colab":{}},"source":["policy_gamma = 0.9\n","alpha = 3e-4\n","model = ActorCritic(len(sampled_train_loader),10, alpha, policy_gamma)\n","optimizer = optim.Adam(model.parameters(), lr=alpha)\n","\n","\n","\n","def oac_iter(mini_batch_size, states, actions, log_probs, returns, advantage, values):\n","\n","    batch_size = states.size(0)\n","\n","    for _ in range(batch_size // mini_batch_size):\n","        rand_ids = np.random.randint(0, batch_size, mini_batch_size)\n","        # print(len(states[0]))\n","        # print(states[rand_ids, :])\n","        # print(actions[rand_ids, :])\n","        # print(log_probs[rand_ids, :])\n","        # print(returns[rand_ids, :])\n","        # print(advantage[rand_ids, :])\n","        # print(values[rand_ids, :])\n","        yield states[rand_ids, :], actions[rand_ids, :], log_probs[rand_ids, :], returns[rand_ids, :], advantage[rand_ids, :], values[rand_ids, :]\n","\n","\n","\n","def oac_update(pi, mini_batch_size, states, actions, log_probs, returns, advantages, values):\n","\n","    for _ in range(ppo_epochs):\n","        for state, action, old_log_probs, return_, advantage, value in oac_iter(mini_batch_size, states, actions, log_probs, returns, advantages, values):\n","\n","            \n","\n","            actor_loss  = - log_probs*returns \n","            critic_loss = (return_ - value)\n","\n","            loss = critic_loss*actor_loss\n","\n","\n","            optimizer.zero_grad()\n","            loss = Variable(loss, requires_grad=True)\n","            loss.backward()\n","            optimizer.step()\n","\n","\n","\n","\n","\n","\n","        "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DyM_prlwdTKY","colab_type":"code","colab":{}},"source":["def OAC(\n","    env, #open-ai environment\n","    num_episodes:int,\n","    pi:PiApproximationWithNN,\n","    data_weights: Data_Weight\n","    ):\n","    \"\"\"\n","    implement REINFORCE algorithm with and without baseline.\n","\n","    input:\n","        env: target environment; openai gym\n","        num_episode: #episodes to iterate\n","        pi: policy\n","        V: baseline\n","    output:\n","        a list that includes the G_0 for every episodes.\n","    \"\"\"    \n","    max_episode_num = num_episodes\n","    \n","    numsteps = []\n","    avg_numsteps = []\n","    all_rewards = []\n","    mini_batch_size  = 4\n","    ppo_epochs       = 1\n"," \n","\n","    for episode in range(max_episode_num):\n","       \n","        stateLoader = sampled_train_loader # state is the dataloader. 4 images\n","        log_probs = []      # required for reinforce\n","        rewards = []        # accuracy after observing x batches. A sequential model. Check how NN perform for sequential models\n","        values = []\n","        states = []\n","        actions = []\n","        masks = []\n","     \n","\n","        stateIter = iter(stateLoader)\n","       \n","        for steps in range(0,len(stateLoader)): # range (0, 100)\n","           \n","            state, trueLabels = stateIter.next()\n","  \n","            value = pi.critic(state)\n","            action, log_prob = pi.actor(state)\n","            reward, done = env.step(action,state,trueLabels, steps)\n","\n","            log_probs.append(log_prob)\n","            values.append(value)\n","            rewards.append(reward)\n","            masks.append(torch.FloatTensor(1))\n","     \n","            # print(value)\n","            states.append(state)\n","            actions.append(action)\n","\n","            # log_probs = [item for sublist in log_probs_list for item in sublist]\n","            # rewards = [item for sublist in rewards_list for item in sublist]\n","\n","            \n","            \n","\n","            if done:\n","              \n","              # print(\"* * * after all steps len of reward is \", len(rewards)) # 4*100 = 400\n","\n","              weights = data_weights.data_manipulation(sampled_val_loader) #400\n","              # returns = pi.discountedWeigthedRewards(rewards, weights)\n","              next_value = value\n","              returns = compute_gae(next_value, rewards, masks, values)\n","              returns   = torch.stack(returns).detach()\n","              log_probs = torch.stack(log_probs).detach()\n","              values    = torch.stack(values).detach()\n","              states    = torch.stack(states)\n","              actions   = torch.stack(actions)\n","              advantage = returns - values\n","\n","              # pi.update(rewards, log_probs, weighted_reward) #update theta\n","              oac_update(pi, mini_batch_size, states, actions, log_probs, returns, advantage, values)\n","              data_weights.update(weights) #update fi\n","\n","              numsteps.append(steps)\n","              avg_numsteps.append(np.mean(numsteps[-10:]))\n","              all_rewards.append(np.sum(rewards))\n","              if episode % 1 == 0:\n","                print(\"episode: {}, total reward: {}, average_reward: {}, length: {}\\n\".format(episode, np.round(np.sum(rewards), decimals = 3),  np.round(np.mean(all_rewards[-10:]), decimals = 3), steps))\n","              break\n","          \n","            # state = new_state\n","    \n","    plt.plot(numsteps)\n","    plt.plot(all_rewards)\n","    plt.xlabel('Episode')\n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LEThnI2pD9Y_","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}